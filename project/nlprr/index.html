<!DOCTYPE html>
 <html lang="en">
  <head>
		<title>Kevin Shao</title>
		<!-- link to main stylesheet -->
		<link rel="stylesheet" type="text/css" href="/css/project-styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Exo+2:wght@900&family=Oswald:wght@500&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,400;1,300&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" rel="stylesheet">
    <script src="/test2.js"></script>
	</head>
	<body>
    <header>
      <section id="nav-bar">
        <h1>Kevin Shao</h1>
        <nav>
          <a href="/#profile-section">Home</a>
          <a href="/#research">Research</a>
          <a href="/#project">Project</a>
          <a href="/#teaching">Teaching</a>
          <a href="/#publications">Publications</a>
        </nav>
      </section>
    </header>

    <section id="project-page">
      <h2>Responsibility and Representation in Natural Language Processing (NLP) Data Practice</h2>
      <div class="tag-container" style="margin-top: 10px;">
        <span class="tag">HCI</span>
        <span class="tag">NLP</span>
        <span class="tag">Fairness, Representation, and Bias</span>
      </div>
      <h4>PIs: Dr. Jay Cunningham, Professors Julie Kientz and Daniela Rosner</h4>
      <!--<div class="buttons">
        <a href="https://www.engr.washington.edu/news/article/2023-04-04/job-experience-classroom" class="button">UW ECE</a>
      </div>-->
      <p>
        The project aimed to understand how NLP/ML technologists' design decisions impact fairness,
        representation, and bias particularly among linguistically and ethnically diverse user groups.
        The study focuses on consensus-building strategies, success metrics, and quality assurance methods
        in NLP data production. It is examining professionals' perspectives and experiences in addressing
        issues of exclusion, discrimination, and bias in NLP dataset production. By exploring the tensions
        and challenges in NLP data practices such as transcription, annotation, and analysis, along with the
        involvement of diverse users, the study seeks to gain a holistic perspective of approaches.
        The research team emphasizes strategies toward increasing fairness and amplifying diverse
         user representation, thereby enhancing AI responsibility within NLP data practices. The ultimate
         goal is to outline a landscape to address the imbalance of power and agency in these processes,
         thereby promoting more responsible and equitable AI development practices.
      </p>
      <br>
      <p>
         Building upon the critical recognition that diversity among data annotators is essential for
        creating unbiased conversational speech and text systems, this study investigates the broader
         implications of these practices. It is informed by prior research highlighting the challenges posed by misaligned
         grounded-truth evaluation metrics, the lack of diversity among data annotators, and the minimal
         involvement of diverse communities in the development of NLP systems.

      </p>

      <!--<img src="/img/capstone.png" alt="TBD">-->
      <div class="proj2-intro">
        <h3 class="title">Method</h3>
        <p>
          This study used a mixed methods approach to investigate current data practices among NLP practitioners.
          <ul>
            <li>
              An online questionnaire administered via Typeform, which gathered responses from 47
              eligible professionals. The recruitment targeted individuals with substantial experience
              in NLP data work.
            </li>
            <li>
              A virtual semi-structured focus group interviews with 5 NLP professionals that was selected
              based on their willingness and survey responses.
            </li>
          </ul>
        </p>
      </div>

      <p>
        Survey insights report analyzed using Power BI: <a href="https://drive.google.com/file/d/1_4t5ga2wsc0Q8o8xhSIag5Bw7ReSGCKm/view">LINK</a>

     </p>
     <h3 class="title">Publication</h3>
     <p>
      Jay L. Cunningham, Kevin Shao, Nathanael Elias Mengist, Rock Pang, et al. 2025. Advancing NLP Data
      Equity: Practitioner Responsibility and Accountability in NLP Data Practices. (Under Review ACM FAccT 2025)
     </p>
      <h3 class="title">More Info Coming Soon</h3>

      <!--<h3 class="title">How Does It Work?</h3>
      <img src="/img/ev-sys-dig.png" alt="Image 2" class="full">
      <p>
        The diagram above shows the full system design. The team used hardware that interprets firmware data of Mach-E and
        implemented Bluetooth connectivity that allows for real-time updates of charging station statistics to the cloud server.
      </p>
      <h4 class="subtitle">Hardware System Design</h4>
      <div class="image-text-container">
        <img src="/img/hardware-system.png" alt="Image 1" class="image-50">
        <div class="text-50">
          <p>
            The hardware system is made up of several modules with different functionalities, among
            which the most important ones are the OBD2, the Charge Angel AVFS Box (installed with
            Raspberry Pi inside) and the Wireshark Box.
            <ul>
              <li>AVFS/RPi triggers data collection upon detecting a "plug in" event via CAN from J1772 or CCS1 ports.</li>
              <li>Wireshark Box outputs ethernet packets; RPi records these using tcpdump.</li>
              <li>Once unplugged, RPi saves Ethernet traffic as a pcap file and logs CAN data from plug in to unplug.</li>
              <li>Data is retrieved by downloading zipped files from RPi's remote server to localhost.</li>
              <li>Raw SoC data is sent to phones in real-time using the Bluetooth module in the Charge Angel AVFS Box.</li>
            </ul>
          </p>
        </div>
      </div>
      <h4 class="subtitle">Software System Design</h4>
      <img src="/img/software-system.png" alt="Image 2" class="full">
      <p>
        The implementation of the software system is composed of four stages:
        <ul>
          <li>Import the raw data from the raspberry pi to Azure database.</li>
          <li>Perform backend computations on the cloud server.</li>
          <li>Identify EV chargers’ health conditions and approximate charging time via computation results.</li>
          <li>Export results to iOS App to display.</li>
        </ul>
      </p>
      <br>
      <div class="image-text-container">
        <img src="/img/clould-computing-system.png" alt="Image 1" class="image-50">
        <div class="text-50">
          <p>
            The cloud computing portion of the system occurs sequentially.
            <ul>
              <li>Raw charging data is sent from the iOS app to Azure SQL via an Azure Function HTTP
                  trigger, using a POST request implemented in Swift.</li>
              <li>The Azure function loads and uses the appropriate AC or DC machine learning model,
                  based on the 'charge_type' parameter, to classify the charger and estimate charge time.</li>
              <li>After processing, results are formatted and asynchronously sent back to the iOS app
                  via an HTTP response, and simultaneously uploaded to the SQL database.</li>
            </ul>
            To be clear, the HTTP response is not generated by the 'model.predict' function; instead,
            it is the Azure UploadData function that handles this task. However, the system diagram
            was designed to show sequentiality, in which ‘model.predict’ is the last event that happens
            before our data is uploaded and returned to the user.
          </p>
        </div>
      </div>
      <h4 class="subtitle">UI/UX System Design</h4>
      <div class="image-text-container">
        <img src="/img/ux-system.png" alt="Image 1" class="image-50">
        <div class="text-50">
          <p>
            The UI/UX system design is composed of two subsystems. The first subsystem includes
            retrieving raw data from the Charge Angel AVSF Box used by the hardware team. From
            the Bluetooth module, the iOS app will display real-time data. The second subsystem
            includes retrieving data from the cloud which we get from the Azure Database and
            display the charging data on the iOS app.
          </p>
        </div>
      </div>


      <h3 class="title">Results and Analysis</h3>
      <h4 class="subtitle">Hardware</h4>
      <ul>
        <li>Raspberry Pi utilizes Bluetooth for stable file transfer to the app, supporting full file storage system implementation.</li>
        <li>Script implemented on Raspberry Pi for automatic Bluetooth advertising upon power-up, enhancing user convenience.</li>
        <li>Automatic start-up of Bluetooth advertising takes approximately 45 seconds, due to inherent hardware and protocol initialization delays.</li>
      </ul>
      <h4 class="subtitle">Software</h4>
      <p>
        The result of ML models are listed below. The performance of DC models are better than ACs’, which is caused by the lack of AC data.
      </p>
      <img src="/img/Train-result.png" alt="Image 2" class="full">
      <p>
        As demostrated in the table below, our Azure function which receives, classifies, and returns data often completes operations in the range of 100-200 milliseconds, with the worst-case scenario cold starts taking a few seconds. This allows users to get charge time updates in real time.
      </p>
      <img src="/img/Azure-Function-performance.png" alt="Image 2" class="full">
      <h4 class="subtitle">UI/UX System</h4>
      <p>
        The map functionality worked as expected by showing nearby charging stations, routing the user
        to the station using Apple maps, and allowing the user to favorite stations and see information
        about them. The search functionality also worked to allow users to look for a specific charging
        station and view detailed information on the station. The live charging updates also displayed
        voltage draw, current draw, and charging rate. Additional details like charging time and the
        classification of the charger (broken or working) were also added. The bluetooth functionality
        was also working as expected where we were able to see the files received.
      </p>
      <div class="image-container">
        <figure>
          <img src="/img/cap4.png" alt="Image 1" class="image">
        </figure>
        <figure>
          <img src="/img/cap6.png" alt="Image 1" class="image">
        </figure>
        <figure>
          <img src="/img/cap7.png" alt="Image 2" class="image">
        </figure>
        <figure>
          <img src="/img/cap5.png" alt="Image 1" class="image">
        </figure>
        <figure>
          <img src="/img/cap8.png" alt="Image 2" class="image">
        </figure>
      </div>-->
    </section>


		<footer>
      <div class="footer-section left">
        <p id="last-updated">Last Updated: <span id="update-date"></span></p>
      </div>
      <div class="footer-section center">
        <p>
          <!--Site created by Kevin Shao. All other attributions cited in page source.-->
          © Kevin Shao. All Rights Reserved.
        </p>
      </div>
      <div class="footer-section right"></div> <!-- Invisible spacer -->
    </footer>
	</body>
</html>